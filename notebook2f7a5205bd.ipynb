{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T12:16:20.276829Z","iopub.execute_input":"2026-01-06T12:16:20.277090Z","iopub.status.idle":"2026-01-06T12:16:28.619456Z","shell.execute_reply.started":"2026-01-06T12:16:20.277064Z","shell.execute_reply":"2026-01-06T12:16:28.618237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ECG Image to Time-Series Extraction - FIXED DATA LOADING\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom tqdm import tqdm\nimport warnings\nimport gc\nimport multiprocessing\nwarnings.filterwarnings('ignore')\n\nnp.random.seed(42)\ntorch.manual_seed(42)\n\n# Device setup\nif torch.cuda.is_available():\n    device = torch.device('cuda')\n    torch.backends.cudnn.benchmark = True\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    device = torch.device('cpu')\n    torch.set_num_threads(multiprocessing.cpu_count())\n    print(f\"CPU: {multiprocessing.cpu_count()} cores\")\n\nprint(\"=\"*80)\nprint(\"ECG IMAGE TO TIME-SERIES - FIXED VERSION\")\nprint(\"=\"*80)\n\n# ============================================================================\n# DATA EXPLORATION WITH PROPER CSV LOADING\n# ============================================================================\n\ndef explore_data():\n    base_path = '/kaggle/input/physionet-ecg-image-digitization'\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"DATA VERIFICATION\")\n    print(\"=\"*80)\n    \n    # Load train.csv and test.csv\n    train_csv_path = os.path.join(base_path, 'train.csv')\n    test_csv_path = os.path.join(base_path, 'test.csv')\n    \n    train_df = None\n    test_df = None\n    \n    if os.path.exists(train_csv_path):\n        train_df = pd.read_csv(train_csv_path)\n        print(f\"\\ntrain.csv loaded: {train_df.shape}\")\n        print(f\"Columns: {list(train_df.columns)}\")\n        print(f\"Sample rows:\\n{train_df.head(20)}\")\n        print(f\"Unique values in first column: {train_df.iloc[:, 0].nunique()}\")\n    else:\n        print(\"‚ö†Ô∏è  train.csv not found!\")\n    \n    if os.path.exists(test_csv_path):\n        test_df = pd.read_csv(test_csv_path)\n        print(f\"\\ntest.csv loaded: {test_df.shape}\")\n        print(f\"Columns: {list(test_df.columns)}\")\n        print(f\"Sample rows:\\n{test_df.head(20)}\")\n    else:\n        print(\"‚ö†Ô∏è  test.csv not found!\")\n    \n    # Check train folder structure\n    train_path = os.path.join(base_path, 'train')\n    patient_dirs = []\n    if os.path.exists(train_path):\n        patient_dirs = sorted([d for d in os.listdir(train_path) \n                              if os.path.isdir(os.path.join(train_path, d))])\n        print(f\"\\nTotal patient folders: {len(patient_dirs)}\")\n        \n        # Check first few patient folders\n        for i, pid in enumerate(patient_dirs[:3]):\n            p_folder = os.path.join(train_path, pid)\n            files = sorted(os.listdir(p_folder))\n            csv_files = [f for f in files if f.endswith('.csv')]\n            png_files = [f for f in files if f.endswith('.png')]\n            print(f\"\\nPatient {pid}:\")\n            print(f\"  CSV files: {csv_files}\")\n            print(f\"  PNG files ({len(png_files)}): {png_files[:3]}...\")\n            \n            # Check CSV structure\n            if csv_files:\n                csv_path = os.path.join(p_folder, csv_files[0])\n                df = pd.read_csv(csv_path)\n                print(f\"  CSV shape: {df.shape}\")\n                print(f\"  CSV columns: {list(df.columns)[:5]}...\")\n    \n    # Check test folder\n    test_path = os.path.join(base_path, 'test')\n    if os.path.exists(test_path):\n        test_files = sorted([f for f in os.listdir(test_path) if f.endswith('.png')])\n        print(f\"\\nTest images: {len(test_files)}\")\n        if test_files:\n            print(f\"  Sample: {test_files[:5]}\")\n    \n    return base_path, train_df, test_df, patient_dirs\n\nbase_path, train_df, test_df, patient_dirs = explore_data()\n\n# ============================================================================\n# DATASET WITH PROPER CSV MAPPING\n# ============================================================================\n\nclass ECGDataset(Dataset):\n    def __init__(self, base_path, patient_ids, transform=None, is_test=False, max_len=5000):\n        \"\"\"\n        Args:\n            base_path: Base path to data\n            patient_ids: List of patient IDs or DataFrame\n            transform: Image transforms\n            is_test: Whether this is test set\n            max_len: Maximum sequence length\n        \"\"\"\n        self.base_path = base_path\n        self.transform = transform\n        self.is_test = is_test\n        self.max_len = max_len\n        self.samples = []\n        \n        if is_test:\n            # Test set: just load images\n            test_dir = os.path.join(base_path, 'test')\n            test_files = sorted([f for f in os.listdir(test_dir) if f.endswith('.png')])\n            for f in test_files:\n                self.samples.append({\n                    'patient_id': f.replace('.png', ''),\n                    'image_path': os.path.join(test_dir, f)\n                })\n        else:\n            # Training set: load images and corresponding time-series\n            train_dir = os.path.join(base_path, 'train')\n            \n            # Handle both list of IDs and DataFrame\n            if isinstance(patient_ids, pd.DataFrame):\n                patient_ids = patient_ids['patient_id'].unique() if 'patient_id' in patient_ids.columns else patient_ids.iloc[:, 0].unique()\n            \n            for pid in patient_ids:\n                p_folder = os.path.join(train_dir, str(pid))\n                if not os.path.exists(p_folder):\n                    continue\n                \n                # Get all images for this patient\n                images = sorted([f for f in os.listdir(p_folder) if f.endswith('.png')])\n                \n                # Get CSV file for this patient\n                csv_file = os.path.join(p_folder, f\"{pid}.csv\")\n                \n                if os.path.exists(csv_file):\n                    for img in images:\n                        self.samples.append({\n                            'patient_id': pid,\n                            'image_path': os.path.join(p_folder, img),\n                            'csv_path': csv_file\n                        })\n        \n        print(f\"  Loaded {len(self.samples)} samples\")\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        sample = self.samples[idx]\n        \n        # Load image\n        image = cv2.imread(sample['image_path'])\n        if image is None:\n            print(f\"‚ö†Ô∏è  Failed to load: {sample['image_path']}\")\n            image = np.zeros((512, 512, 3), dtype=np.uint8)\n        else:\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.is_test:\n            return image, sample['patient_id']\n        \n        # Load target from CSV\n        target = torch.zeros(12, self.max_len)\n        \n        if 'csv_path' in sample and os.path.exists(sample['csv_path']):\n            try:\n                df = pd.read_csv(sample['csv_path'])\n                df = df.fillna(0.0)\n                \n                # Extract 12 leads\n                for lead_idx in range(min(12, len(df.columns))):\n                    lead_data = df.iloc[:, lead_idx].values.astype(np.float32)\n                    length = min(len(lead_data), self.max_len)\n                    target[lead_idx, :length] = torch.from_numpy(lead_data[:length])\n                    \n            except Exception as e:\n                print(f\"Error loading {sample['csv_path']}: {e}\")\n        \n        return image, target, sample['patient_id']\n\n\ndef get_transforms(is_train=True, img_size=(384, 384)):\n    if is_train:\n        return transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize(img_size),\n            transforms.RandomRotation(degrees=2),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    else:\n        return transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize(img_size),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n\n# ============================================================================\n# MODEL\n# ============================================================================\n\nclass ECGEncoder(nn.Module):\n    def __init__(self, latent_dim=256):\n        super().__init__()\n        \n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(256, 256, 3, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.AdaptiveAvgPool2d(1)\n        )\n        \n        self.fc = nn.Linear(256, latent_dim)\n    \n    def forward(self, x):\n        x = self.encoder(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\nclass ECGDecoder(nn.Module):\n    def __init__(self, latent_dim=256, seq_len=5000, num_leads=12):\n        super().__init__()\n        \n        self.seq_len = seq_len\n        self.fc_init = nn.Linear(latent_dim, 128)\n        self.lstm1 = nn.LSTM(128, 256, batch_first=True, bidirectional=True)\n        self.dropout1 = nn.Dropout(0.2)\n        self.lstm2 = nn.LSTM(512, 128, batch_first=True, bidirectional=True)\n        self.fc_out = nn.Linear(256, num_leads)\n    \n    def forward(self, x):\n        x = self.fc_init(x)\n        x = x.unsqueeze(1).repeat(1, self.seq_len, 1)\n        x, _ = self.lstm1(x)\n        x = self.dropout1(x)\n        x, _ = self.lstm2(x)\n        x = self.fc_out(x)\n        x = x.permute(0, 2, 1)\n        return x\n\n\nclass ECGModel(nn.Module):\n    def __init__(self, latent_dim=256, seq_len=5000, num_leads=12):\n        super().__init__()\n        self.encoder = ECGEncoder(latent_dim)\n        self.decoder = ECGDecoder(latent_dim, seq_len, num_leads)\n    \n    def forward(self, x):\n        latent = self.encoder(x)\n        output = self.decoder(latent)\n        return output\n\n# ============================================================================\n# SNR CALCULATION\n# ============================================================================\n\ndef calculate_snr_fixed(pred, target, eps=1e-10):\n    pred = pred.detach().cpu().numpy()\n    target = target.detach().cpu().numpy()\n    \n    snr_values = []\n    \n    for i in range(pred.shape[0]):\n        p = pred[i] - np.mean(pred[i], axis=1, keepdims=True)\n        t = target[i] - np.mean(target[i], axis=1, keepdims=True)\n        \n        signal_power = np.sum(t ** 2) + eps\n        noise_power = np.sum((p - t) ** 2) + eps\n        snr_db = 10 * np.log10(signal_power / noise_power)\n        \n        if not np.isnan(snr_db) and not np.isinf(snr_db):\n            snr_values.append(snr_db)\n    \n    return np.mean(snr_values) if snr_values else float('nan')\n\n# ============================================================================\n# TRAINING WITH VISUALIZATION\n# ============================================================================\n\ndef train_epoch(model, loader, criterion, optimizer, device, scaler=None):\n    model.train()\n    total_loss = 0\n    total_snr = 0\n    num_batches = 0\n    \n    pbar = tqdm(loader, desc='Training')\n    \n    for batch_idx, batch in enumerate(pbar):\n        try:\n            images, targets, _ = batch\n            images = images.to(device)\n            targets = targets.to(device)\n            \n            if torch.isnan(images).any() or torch.isnan(targets).any():\n                continue\n            \n            optimizer.zero_grad()\n            \n            if scaler is not None:\n                with torch.cuda.amp.autocast():\n                    outputs = model(images)\n                    min_len = min(outputs.shape[2], targets.shape[2])\n                    outputs = outputs[:, :, :min_len]\n                    targets = targets[:, :, :min_len]\n                    loss = criterion(outputs, targets)\n                \n                if torch.isnan(loss):\n                    continue\n                \n                scaler.scale(loss).backward()\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                outputs = model(images)\n                min_len = min(outputs.shape[2], targets.shape[2])\n                outputs = outputs[:, :, :min_len]\n                targets = targets[:, :, :min_len]\n                loss = criterion(outputs, targets)\n                \n                if torch.isnan(loss):\n                    continue\n                \n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                optimizer.step()\n            \n            snr = calculate_snr_fixed(outputs, targets)\n            \n            if not np.isnan(snr):\n                total_loss += loss.item()\n                total_snr += snr\n                num_batches += 1\n            \n            pbar.set_postfix({\n                'loss': f'{loss.item():.4f}',\n                'snr': f'{snr:.2f}' if not np.isnan(snr) else 'NaN'\n            })\n            \n        except Exception as e:\n            print(f\"‚ùå Error in batch {batch_idx}: {e}\")\n            continue\n    \n    if num_batches == 0:\n        return float('nan'), float('nan')\n    \n    return total_loss / num_batches, total_snr / num_batches\n\n\ndef validate(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    total_snr = 0\n    num_batches = 0\n    \n    with torch.no_grad():\n        pbar = tqdm(loader, desc='Validation')\n        \n        for batch in pbar:\n            try:\n                images, targets, _ = batch\n                images = images.to(device)\n                targets = targets.to(device)\n                \n                outputs = model(images)\n                min_len = min(outputs.shape[2], targets.shape[2])\n                outputs = outputs[:, :, :min_len]\n                targets = targets[:, :, :min_len]\n                \n                loss = criterion(outputs, targets)\n                \n                if torch.isnan(loss):\n                    continue\n                \n                snr = calculate_snr_fixed(outputs, targets)\n                \n                if not np.isnan(snr):\n                    total_loss += loss.item()\n                    total_snr += snr\n                    num_batches += 1\n                \n                pbar.set_postfix({\n                    'loss': f'{loss.item():.4f}',\n                    'snr': f'{snr:.2f}' if not np.isnan(snr) else 'NaN'\n                })\n                \n            except Exception as e:\n                continue\n    \n    if num_batches == 0:\n        return float('nan'), float('nan')\n    \n    return total_loss / num_batches, total_snr / num_batches\n\n\ndef plot_training_history(history):\n    \"\"\"Plot training curves\"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n    \n    # Loss plot\n    axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n    axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n    axes[0].set_xlabel('Epoch')\n    axes[0].set_ylabel('Loss')\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].legend()\n    axes[0].grid(True)\n    \n    # SNR plot\n    axes[1].plot(history['train_snr'], label='Train SNR', marker='o')\n    axes[1].plot(history['val_snr'], label='Val SNR', marker='s')\n    axes[1].set_xlabel('Epoch')\n    axes[1].set_ylabel('SNR (dB)')\n    axes[1].set_title('Training and Validation SNR')\n    axes[1].legend()\n    axes[1].grid(True)\n    \n    plt.tight_layout()\n    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n    print(\"‚úÖ Saved training_history.png\")\n    plt.show()\n\n# ============================================================================\n# MAIN PIPELINE\n# ============================================================================\n\ndef main():\n    print(\"\\n\" + \"=\"*80)\n    print(\"TRAINING PIPELINE\")\n    print(\"=\"*80)\n    \n    config = {\n        'img_size': (384, 384),\n        'batch_size': 16,\n        'num_epochs': 1,\n        'learning_rate': 1e-4,\n        'latent_dim': 256,\n        'seq_length': 5000,\n        'num_leads': 12,\n        'num_workers': 4,\n        'warmup_epochs': 2\n    }\n    \n    print(\"\\nConfiguration:\")\n    for k, v in config.items():\n        print(f\"  {k}: {v}\")\n    \n    # Use patient directories directly\n    from sklearn.model_selection import train_test_split\n    \n    print(f\"\\nTotal patients available: {len(patient_dirs)}\")\n    train_ids, val_ids = train_test_split(patient_dirs, test_size=0.15, random_state=42)\n    \n    print(f\"Train patients: {len(train_ids)}\")\n    print(f\"Val patients: {len(val_ids)}\")\n    \n    # Create datasets\n    print(\"\\nCreating datasets...\")\n    train_dataset = ECGDataset(base_path, train_ids, \n                               transform=get_transforms(True, config['img_size']),\n                               max_len=config['seq_length'])\n    \n    val_dataset = ECGDataset(base_path, val_ids,\n                            transform=get_transforms(False, config['img_size']),\n                            max_len=config['seq_length'])\n    \n    train_loader = DataLoader(train_dataset, \n                             batch_size=config['batch_size'],\n                             shuffle=True,\n                             num_workers=config['num_workers'],\n                             pin_memory=torch.cuda.is_available())\n    \n    val_loader = DataLoader(val_dataset,\n                           batch_size=config['batch_size'],\n                           shuffle=False,\n                           num_workers=config['num_workers'],\n                           pin_memory=torch.cuda.is_available())\n    \n    # Model\n    print(\"\\nInitializing model...\")\n    model = ECGModel(config['latent_dim'], config['seq_length'], config['num_leads']).to(device)\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Parameters: {total_params:,}\")\n    \n    criterion = nn.MSELoss()\n    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=1e-5)\n    \n    from torch.optim.lr_scheduler import CosineAnnealingLR\n    scheduler = CosineAnnealingLR(optimizer, T_max=config['num_epochs'] - config['warmup_epochs'])\n    \n    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n    \n    # Training\n    history = {'train_loss': [], 'val_loss': [], 'train_snr': [], 'val_snr': []}\n    best_val_snr = -1000\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STARTING TRAINING\")\n    print(\"=\"*80)\n    \n    for epoch in range(config['num_epochs']):\n        print(f\"\\nEpoch {epoch+1}/{config['num_epochs']}\")\n        print(\"-\" * 80)\n        \n        if epoch < config['warmup_epochs']:\n            lr = config['learning_rate'] * (epoch + 1) / config['warmup_epochs']\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = lr\n            print(f\"Warmup LR: {lr:.6f}\")\n        \n        train_loss, train_snr = train_epoch(model, train_loader, criterion, optimizer, device, scaler)\n        val_loss, val_snr = validate(model, val_loader, criterion, device)\n        \n        if epoch >= config['warmup_epochs']:\n            scheduler.step()\n        \n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['train_snr'].append(train_snr)\n        history['val_snr'].append(val_snr)\n        \n        print(f\"\\nüìä Epoch Summary:\")\n        print(f\"  Train Loss: {train_loss:.4f} | Train SNR: {train_snr:.2f} dB\")\n        print(f\"  Val Loss: {val_loss:.4f} | Val SNR: {val_snr:.2f} dB\")\n        print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n        \n        if not np.isnan(val_snr) and val_snr > best_val_snr:\n            best_val_snr = val_snr\n            torch.save(model.state_dict(), 'best_model.pth')\n            print(f\"  ‚úÖ Best model saved (SNR: {best_val_snr:.2f} dB)\")\n        \n        if np.isnan(train_loss) or np.isnan(val_loss):\n            print(\"\\n‚ö†Ô∏è  Training collapsed. Stopping.\")\n            break\n        \n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        gc.collect()\n    \n    # Plot training curves\n    plot_training_history(history)\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"‚úÖ TRAINING COMPLETE\")\n    print(f\"Best Val SNR: {best_val_snr:.2f} dB\")\n    print(f\"{'='*80}\")\n    \n    return model, history\n\n\ndef generate_submission(model, base_path, device):\n    \"\"\"Generate submission in correct format\"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"GENERATING SUBMISSION\")\n    print(\"=\"*80)\n    \n    # Get test files directly from directory\n    test_dir = os.path.join(base_path, 'test')\n    test_files = sorted([f for f in os.listdir(test_dir) if f.endswith('.png')])\n    test_ids = [f.replace('.png', '') for f in test_files]\n    \n    print(f\"Test images: {len(test_ids)}\")\n    \n    test_dataset = ECGDataset(base_path, test_ids,\n                             transform=get_transforms(False, (384, 384)),\n                             is_test=True, max_len=5000)\n    \n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n                            num_workers=4, pin_memory=torch.cuda.is_available())\n    \n    model.eval()\n    submissions = []\n    lead_names = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n    \n    with torch.no_grad():\n        for images, patient_ids in tqdm(test_loader, desc='Inference'):\n            images = images.to(device)\n            outputs = model(images).cpu().numpy()\n            \n            for b_idx, pid in enumerate(patient_ids):\n                for t_idx in range(outputs.shape[2]):\n                    for l_idx, lead in enumerate(lead_names):\n                        submissions.append({\n                            'id': f\"{pid}_{t_idx}_{lead}\",\n                            'value': float(outputs[b_idx, l_idx, t_idx])\n                        })\n    \n    df = pd.DataFrame(submissions)\n    df.to_csv('submission.csv', index=False)\n    print(f\"‚úÖ Saved: submission.csv ({len(df)} rows)\")\n    print(f\"\\nSample submission:\")\n    print(df.head(10))\n    return df\n\n\n# ============================================================================\n# RUN\n# ============================================================================\n\nif __name__ == \"__main__\":\n    if len(patient_dirs) > 0:\n        model, history = main()\n        submission = generate_submission(model, base_path, device)\n    else:\n        print(\"‚ùå No patient directories found!\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"‚úÖ PIPELINE COMPLETE\")\n    print(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:14:16.633933Z","iopub.execute_input":"2026-01-07T17:14:16.634544Z","iopub.status.idle":"2026-01-07T17:32:55.818292Z","shell.execute_reply.started":"2026-01-07T17:14:16.634507Z","shell.execute_reply":"2026-01-07T17:32:55.817448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nstate_dict = torch.load(path, map_location=\"cpu\")\nprint(type(state_dict))\nlist(state_dict.keys())[:15]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:39:01.297735Z","iopub.execute_input":"2026-01-07T17:39:01.298370Z","iopub.status.idle":"2026-01-07T17:39:01.315642Z","shell.execute_reply.started":"2026-01-07T17:39:01.298343Z","shell.execute_reply":"2026-01-07T17:39:01.315026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.remove(\"/kaggle/working/best_model.pth\")\nprint(\"Deleted model file\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T18:38:26.123781Z","iopub.execute_input":"2026-01-07T18:38:26.124174Z","iopub.status.idle":"2026-01-07T18:38:26.129917Z","shell.execute_reply.started":"2026-01-07T18:38:26.124148Z","shell.execute_reply":"2026-01-07T18:38:26.129192Z"}},"outputs":[{"name":"stdout","text":"Deleted model file\n","output_type":"stream"}],"execution_count":18}]}